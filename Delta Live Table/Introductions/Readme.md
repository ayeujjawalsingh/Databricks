# ğŸ“˜ Delta Live Tables (DLT)

Delta Live Tables (DLT) is a framework by **Databricks** that makes it easy to create **ETL pipelines** using **SQL or Python**. It handles table creation, scheduling, monitoring, and error handling automatically.

---

## ğŸ“Œ What is Delta Live Tables?

> Delta Live Tables lets you write **data pipelines** without managing complex Spark jobs or retries.  
You define **what to do**, and DLT manages **how and when** to do it.

---

## âœ… Why Use DLT?

| Feature | What It Means |
|--------|----------------|
| ğŸš€ Easy to use | Use simple SQL or Python functions |
| ğŸ” Automatic scheduling | DLT runs pipelines at intervals or on-demand |
| ğŸ” Monitors itself | Provides logs, errors, lineage graph |
| ğŸ§  Understands dependencies | Runs steps in correct order |
| ğŸ’¾ Stores data as Delta Tables | Data stored in reliable Delta format |
| ğŸ§¹ Cleans bad data | Add simple rules to drop or log invalid rows |
| âš¡ Batch & Streaming | Works with both real-time and batch data |

---

## ğŸ“‚ Basic Components

### 1. `CREATE LIVE TABLE`
Used to define a table in the pipeline.

```sql
CREATE LIVE TABLE raw_orders
AS SELECT * FROM cloud_files("/mnt/orders", "json");
```

### 2. `live.<table_name>`

Used to reference another live table.

```sql
CREATE LIVE TABLE clean_orders
AS SELECT * FROM live.raw_orders WHERE order_status IS NOT NULL;
```

### 3. In Python

```python
import dlt

@dlt.table
def raw_orders():
    return spark.read.format("cloudFiles") \
      .option("cloudFiles.format", "json") \
      .load("/mnt/orders")

@dlt.table
def clean_orders():
    return dlt.read("raw_orders").where("order_status IS NOT NULL")
```

---

## ğŸ” DLT UI Walkthrough

| Section                    | Purpose                                         |
| -------------------------- | ----------------------------------------------- |
| ğŸ”— **Graph View**          | Shows data flow between tables                  |
| ğŸ“ **Run Logs**            | Shows run history, status, logs, and time       |
| ğŸ›¡ï¸ **Data Quality Rules** | Add constraints to drop bad rows                |
| ğŸ§¬ **Schema Evolution**    | Automatically tracks and handles schema changes |
| ğŸ“Š **Monitoring Metrics**  | Shows rows processed, bytes read, duration      |

---

## âš™ï¸ Modes of DLT Pipeline

| Mode                   | Description                              |
| ---------------------- | ---------------------------------------- |
| âœ… **Development Mode** | For testing pipelines quickly            |
| ğŸ”’ **Production Mode** | For stable, regular production workloads |

---

## ğŸ—ƒï¸ Table Types

| Table Type             | Description                       |
| ---------------------- | --------------------------------- |
| `LIVE TABLE`           | Regular managed table             |
| `STREAMING LIVE TABLE` | Table with streaming data support |

---

## ğŸ§¹ Example: Data Cleaning with Rules

```sql
CREATE LIVE TABLE valid_orders
  CONSTRAINT valid_id EXPECT (order_id IS NOT NULL) ON VIOLATION DROP ROW
AS SELECT * FROM live.clean_orders;
```

* If `order_id` is empty, row is **dropped** and logged.

---

## ğŸ“¦ Where Data is Stored

* DLT saves all tables as **Delta tables**
* Can be saved as **managed** (by Databricks) or **external** (your path)
* Can integrate with **Unity Catalog** for data governance

---

## ğŸ“Š Example Data Flow Diagram

```
            Source Files (S3, ADLS, etc.)
                        â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ raw_orders (DLT Table)  â”‚ â† reads JSON
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ clean_orders (DLT)      â”‚ â† filters bad rows
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ gold_orders (DLT)       â”‚ â† does aggregation
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ… Summary

* Delta Live Tables let you create pipelines **faster and safer**
* You write **what to do**, DLT handles **how and when**
* Works with both **batch and streaming**
* Helps you monitor, retry, and clean data easily

---

## ğŸ”— Useful Terms

| Term                    | Meaning                               |
| ----------------------- | ------------------------------------- |
| `cloud_files`           | Autoloader function for reading files |
| `live.<table>`          | Reference to another DLT table        |
| `@dlt.table`            | Python decorator for defining table   |
| `CONSTRAINT ... EXPECT` | Data quality rule                     |
