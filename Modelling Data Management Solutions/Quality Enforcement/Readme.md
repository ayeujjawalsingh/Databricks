# âœ… Data Quality Enforcement

## ðŸ“˜ What is Data Quality Enforcement?

**Data Quality Enforcement** means:
> Making sure the data coming into your system is **correct**, **complete**, and **clean** â€” before you use it for reports, ML, or analytics.

It is like **checking and cleaning groceries** before cooking:
- ðŸ§¼ Remove bad items
- ðŸ·ï¸ Fix labeling
- âœ… Ensure everything is fresh and in expected format

---

## ðŸ—ï¸ Where Do We Apply Quality Enforcement?

Usually applied **after Bronze Layer**, during:
- ðŸ”„ Bronze â†’ Silver (raw â†’ cleaned data)
- ðŸ“Š Silver â†’ Gold (clean â†’ business-ready)

---

## ðŸš¦ Why Is It Important?

| Reason                  | Description |
|-------------------------|-------------|
| ðŸ§¹ Avoid garbage results | Dirty data = wrong analytics |
| ðŸ›‘ Prevent system failures | Nulls or wrong types can crash models |
| ðŸ“Š Build trust           | Business teams need reliable data |
| ðŸ” Enable automation     | Clean data = less manual fixing |
| âœ… Regulatory compliance | Required in healthcare, finance, etc. |

---

## ðŸ” Types of Data Quality Checks

| Check Type      | What It Means                                     | Example |
|------------------|--------------------------------------------------|---------|
| âœ… **Null checks**    | Make sure important columns are not null         | `customer_id IS NOT NULL` |
| ðŸ”¤ **Data type check**| Column is of correct type                        | `amount` should be number |
| ðŸ”¢ **Range check**    | Values are within expected range                 | `age BETWEEN 0 AND 100` |
| ðŸ“… **Format check**   | Check if date is in valid format                 | `yyyy-MM-dd` |
| ðŸŽ¯ **Unique check**   | Values like IDs or emails are not duplicated    | No 2 rows have same `email` |
| ðŸ”— **Foreign key check**| Reference values exist in lookup table        | `customer_id` must exist in `customers` table |

---

## ðŸ› ï¸ How Do We Enforce Quality?

### âœ¨ Option 1: Filter Out Bad Data
Let bad data **go into a separate â€œquarantineâ€ table** so it doesnâ€™t pollute your clean tables.

```python
# Example: Separate good and bad records
good_data = df.filter("amount IS NOT NULL AND amount > 0")
bad_data = df.filter("amount IS NULL OR amount <= 0")

# Save clean data to Silver
good_data.write.format("delta").saveAsTable("silver.orders_clean")

# Save bad data to quarantine
bad_data.write.format("delta").saveAsTable("quarantine.orders_bad")
```

---

### âœ¨ Option 2: Throw Errors Using Expectation (Delta Live Tables)

```python
CREATE LIVE TABLE silver_customers_cleaned
AS SELECT * FROM live.bronze_customers
EXPECT customer_id IS NOT NULL
  ON VIOLATION DROP ROW
EXPECT age BETWEEN 0 AND 120
  ON VIOLATION DROP ROW
```

> âš ï¸ **Delta Live Tables (DLT)** support built-in `EXPECT` clauses for validation

---

## ðŸ§ª Tools & Techniques for Quality Checks

| Tool/Feature                  | Description                                  |
| ----------------------------- | -------------------------------------------- |
| âœ… **Delta Live Tables (DLT)** | Built-in data quality rules using `EXPECT`   |
| âœ… **Great Expectations**      | Open-source tool for automated tests on data |
| âœ… **Spark SQL filters**       | Use WHERE, CASE, IF to clean data            |
| âœ… **Quarantine table**        | Store bad data separately for later fixing   |
| âœ… **Schema enforcement**      | Ensure data matches expected structure       |
| âœ… **Alerts / Logging**        | Notify if bad data rate crosses threshold    |

---

## ðŸ§© Where to Store Invalid (Bad) Data?

It's a good practice to store it in a separate table:

```plaintext
/quarantine/
  â””â”€â”€ orders_bad/
       â”œâ”€â”€ null_amount/
       â””â”€â”€ negative_amount/
```

This helps in:

* Debugging
* Reprocessing later
* Sending alerts

---

## ðŸ§¾ Sample Quality Rules for Common Entities

### ðŸ“¦ Orders Table

| Rule                     | Why?                 |
| ------------------------ | -------------------- |
| `order_id IS NOT NULL`   | Key field            |
| `amount > 0`             | No negative orders   |
| `order_date IS NOT NULL` | Must have order time |

### ðŸ‘¤ Customers Table

| Rule                      | Why?            |
| ------------------------- | --------------- |
| `customer_id IS NOT NULL` | Key field       |
| `email IS NOT NULL`       | Communication   |
| `age BETWEEN 0 AND 120`   | Valid human age |

---

## âœ… Summary â€“ Easy Checklist

| Task                                   | Done? |
| -------------------------------------- | ----- |
| Check for nulls in important columns   | âœ…     |
| Validate number ranges (amount, age)   | âœ…     |
| Check formats for dates, emails        | âœ…     |
| Store bad data separately (quarantine) | âœ…     |
| Apply rules in Bronze â†’ Silver         | âœ…     |

---

## ðŸ“ Real-Life Example Architecture

```plaintext
[ Bronze Table ]
     |
     v
[ Apply Quality Checks ]
     â”œâ”€â”€ Good Data  â”€â”€> Silver Table
     â””â”€â”€ Bad Data   â”€â”€> Quarantine Table
```

---

## ðŸ§  Final Tip

Data Quality is not a one-time thing â€” itâ€™s a **continuous process**.
Start simple, improve rules over time, and always monitor.
